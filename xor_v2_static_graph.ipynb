{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static network\n",
    "import dynet as dy\n",
    "\n",
    "# multilayer perceptron with a single hidden layer\n",
    "# input 2 nodes\n",
    "# hidden layer: 8 nodes, activation: tanh\n",
    "# output layer: 1 node\n",
    "# Ïƒ(V(tanh(Wx+b)))\n",
    "# x: 2x1\n",
    "# W: 8x2\n",
    "# b: 8 vector\n",
    "# V: 8x1\n",
    "\n",
    "# define the parameters\n",
    "m = dy.ParameterCollection()\n",
    "pW = m.add_parameters((8,2)) # _dynet.Parameters\n",
    "pV = m.add_parameters((1,8))\n",
    "pb = m.add_parameters((8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dynet.ComputationGraph at 0x1082f0af8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy.renew_cg() # new computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the parameters to the graph\n",
    "# create Expression representing the network \n",
    "#(the network will include the Expressions \n",
    "# for the Parameters defined in the parameter collection)\n",
    "W = dy.parameter(pW) #W is of type _dynet.Expression\n",
    "V = dy.parameter(pV)\n",
    "b = dy.parameter(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "x = dy.vecInput(2) # an input vector of size 2. _dynet._vecInputExpression\n",
    "output = dy.logistic(V*(dy.tanh((W*x)+b))) # output is _dynet.Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_dynet._vecInputExpression'>\n",
      "<class '_dynet.Expression'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46384352445602417"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now query our network\n",
    "x.set([0,0])\n",
    "output.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to be able to define a loss, so we need an input expression to work against.\n",
    "y = dy.scalarInput(0) # this will hold the correct answer\n",
    "loss = dy.binary_log_loss(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_dynet._inputExpression'>\n",
      "<class '_dynet.Expression'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(type(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = dy.SimpleSGDTrainer(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_dynet.SimpleSGDTrainer"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss before step is: 0.31683480739593506\n",
      "the loss after step is: 0.289972722530365\n"
     ]
    }
   ],
   "source": [
    "# single step optimization/training\n",
    "\n",
    "x.set([1,0])\n",
    "y.set(1)\n",
    "loss_value = loss.value() # this performs a forward through the network.\n",
    "print(\"the loss before step is:\",loss_value)\n",
    "\n",
    "# now do an optimization step\n",
    "loss.backward()  # compute the gradients\n",
    "trainer.update()\n",
    "\n",
    "# see how it affected the loss:\n",
    "loss_value = loss.value(recalculate=True) # recalculate=True means \"don't use precomputed value\"\n",
    "print(\"the loss after step is:\",loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data set\n",
    "def create_xor_instances(num_rounds=2000):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for round in range(num_rounds):\n",
    "        for x1 in 0,1:\n",
    "            for x2 in 0,1:\n",
    "                answer = 0 if x1==x2 else 1\n",
    "                questions.append((x1,x2))\n",
    "                answers.append(answer)\n",
    "    return questions, answers\n",
    "\n",
    "questions, answers = create_xor_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n",
      "[(0, 0), (0, 1), (1, 0), (1, 1)]\n",
      "[0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))\n",
    "print(len(answers))\n",
    "print(questions[:4])\n",
    "print(answers[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), 0), ((0, 1), 1), ((1, 0), 1), ((1, 1), 0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(questions, answers))[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss is: 0.7381698548793793\n",
      "average loss is: 0.7264014571905136\n",
      "average loss is: 0.7161895747979482\n",
      "average loss is: 0.6998325595259667\n",
      "average loss is: 0.6645818127989769\n",
      "average loss is: 0.6091600617766381\n",
      "average loss is: 0.5500666074880531\n",
      "average loss is: 0.49701920384541154\n",
      "average loss is: 0.45168140908496246\n",
      "average loss is: 0.4132660636696964\n",
      "average loss is: 0.38058659604157913\n",
      "average loss is: 0.3525680349774969\n",
      "average loss is: 0.328335457962866\n",
      "average loss is: 0.30719786852066006\n",
      "average loss is: 0.288612498573338\n",
      "average loss is: 0.2721513508545468\n",
      "average loss is: 0.25747434265856795\n",
      "average loss is: 0.24430880694469023\n",
      "average loss is: 0.23243408323878326\n",
      "average loss is: 0.22166996149439364\n",
      "average loss is: 0.21186797930925552\n",
      "average loss is: 0.20290481876878239\n",
      "average loss is: 0.19467725546686385\n",
      "average loss is: 0.18709826192430531\n",
      "average loss is: 0.1800939725853503\n",
      "average loss is: 0.17360130059094026\n",
      "average loss is: 0.1675660497346824\n",
      "average loss is: 0.16194140723465741\n",
      "average loss is: 0.15668673294283256\n",
      "average loss is: 0.15176657587181155\n",
      "average loss is: 0.14714987401858032\n",
      "average loss is: 0.14280929637279768\n",
      "average loss is: 0.13872070012938684\n",
      "average loss is: 0.13486267905497432\n",
      "average loss is: 0.13121618708282975\n",
      "average loss is: 0.12776422196488257\n",
      "average loss is: 0.12449155795815829\n",
      "average loss is: 0.12138452016166411\n",
      "average loss is: 0.11843079167077891\n",
      "average loss is: 0.11561924925260246\n",
      "average loss is: 0.11293982212573699\n",
      "average loss is: 0.1103833701448249\n",
      "average loss is: 0.10794157888656374\n",
      "average loss is: 0.1056068684589594\n",
      "average loss is: 0.10337231405449307\n",
      "average loss is: 0.10123157637667053\n",
      "average loss is: 0.09917884112003834\n",
      "average loss is: 0.0972087658248832\n",
      "average loss is: 0.09531643279937418\n",
      "average loss is: 0.09349730770310853\n",
      "average loss is: 0.09174720296213933\n",
      "average loss is: 0.09006224493771486\n",
      "average loss is: 0.08843884532230045\n",
      "average loss is: 0.08687367517783531\n",
      "average loss is: 0.08536364175459708\n",
      "average loss is: 0.08390586820262667\n",
      "average loss is: 0.08249767488460955\n",
      "average loss is: 0.08113656256667033\n",
      "average loss is: 0.07982019767986011\n",
      "average loss is: 0.07854639880838415\n",
      "average loss is: 0.07731312433391291\n",
      "average loss is: 0.07611846136024988\n",
      "average loss is: 0.07496061594314164\n",
      "average loss is: 0.07383790384394161\n",
      "average loss is: 0.0727487423053692\n",
      "average loss is: 0.0716916423650268\n",
      "average loss is: 0.07066520215144187\n",
      "average loss is: 0.06966810053243534\n",
      "average loss is: 0.06869909145290612\n",
      "average loss is: 0.06775699862049493\n",
      "average loss is: 0.06684071060499622\n",
      "average loss is: 0.06594917648695021\n",
      "average loss is: 0.06508140188541378\n",
      "average loss is: 0.06423644498305245\n",
      "average loss is: 0.06341341333251135\n",
      "average loss is: 0.06261146043281769\n",
      "average loss is: 0.061829783017852934\n",
      "average loss is: 0.06106761816572637\n",
      "average loss is: 0.060324240860063584\n",
      "average loss is: 0.05959896165200189\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "total_loss = 0\n",
    "seen_instances = 0\n",
    "for question, answer in zip(questions, answers):\n",
    "    x.set(question)\n",
    "    y.set(answer)\n",
    "    seen_instances += 1\n",
    "    total_loss += loss.value() # forward\n",
    "    loss.backward()\n",
    "    trainer.update()\n",
    "    if (seen_instances > 1 and seen_instances % 100 == 0):\n",
    "        print(\"average loss is:\",total_loss / seen_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expression 2/1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1 0.9973587989807129\n",
      "1,0 0.9973693490028381\n",
      "0,0 0.0009477359708398581\n",
      "1,1 0.0028826759662479162\n"
     ]
    }
   ],
   "source": [
    "x.set([0,1])\n",
    "print(\"0,1\",output.value())\n",
    "\n",
    "x.set([1,0])\n",
    "print(\"1,0\",output.value())\n",
    "\n",
    "x.set([0,0])\n",
    "print(\"0,0\",output.value())\n",
    "\n",
    "x.set([1,1])\n",
    "print(\"1,1\",output.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.79832745,  3.65569925],\n",
       "       [ 2.30283499,  2.28838158],\n",
       "       [-0.58401084, -0.34022495],\n",
       "       [-0.8143546 , -0.74301219],\n",
       "       [ 0.3137587 ,  0.31108665],\n",
       "       [ 0.08065908,  0.21146144],\n",
       "       [-0.26102978,  0.01117267],\n",
       "       [ 3.64261055, -2.79860806]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.4248147 ,  4.13615608,  1.02193916,  1.61990416, -1.33724082,\n",
       "        -0.76941073,  0.27476746, -5.27176952]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.178240418434143,\n",
       " -0.4626430869102478,\n",
       " 0.8583874106407166,\n",
       " 1.3025976419448853,\n",
       " -1.0519248247146606,\n",
       " -0.6726115345954895,\n",
       " 0.27763113379478455,\n",
       " 1.1828503608703613]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('models/xor_static_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
