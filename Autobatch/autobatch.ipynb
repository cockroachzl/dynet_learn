{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Acceptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceptor LSTM\n",
    "class LstmAcceptor(object):\n",
    "    def __init__(self, in_dim, lstm_dim, out_dim, model):\n",
    "        self.builder = dy.VanillaLSTMBuilder(1, in_dim, lstm_dim, model) # 1 layer\n",
    "        self.W       = model.add_parameters((out_dim, lstm_dim))\n",
    "\n",
    "    def __call__(self, sequence):\n",
    "        s = self.builder.initial_state()\n",
    "        W = self.W.expr() # convert the parameter into an Expession (add it to graph)\n",
    "        outputs = s.transduce(sequence)\n",
    "        result = W*outputs[-1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage:\n",
    "VOCAB_SIZE = 1000 #rows of embedding\n",
    "EMBED_SIZE = 100 #input size of LSTM\n",
    "LSTM_HIDDEN_SIZE = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = dy.Model()\n",
    "trainer = dy.AdamTrainer(m)\n",
    "\n",
    "acceptor = LstmAcceptor(EMBED_SIZE, LSTM_HIDDEN_SIZE, 3, m) # 3 is W's rows, 3 classes output\n",
    "\n",
    "embeds = m.add_lookup_parameters((VOCAB_SIZE, EMBED_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.08813584]\n",
      "[ 1.02386413]\n",
      "[ 0.9687473]\n",
      "[ 0.91334796]\n",
      "[ 0.85537948]\n",
      "[ 0.79329775]\n",
      "[ 0.72606927]\n",
      "[ 0.65342158]\n",
      "[ 0.5763431]\n",
      "[ 0.49758144]\n"
     ]
    }
   ],
   "source": [
    "# training code\n",
    "sum_of_losses = 0.0\n",
    "for epoch in range(10):\n",
    "    for sequence,label in [((1,4,5,1),1), ((42,1),2), ((56,2,17),1)]:\n",
    "        dy.renew_cg() # new computation graph\n",
    "        vecs = [embeds[i] for i in sequence]\n",
    "        preds = acceptor(vecs)\n",
    "        loss = dy.pickneglogsoftmax(preds, label)\n",
    "        sum_of_losses += loss.npvalue()\n",
    "        loss.backward()\n",
    "        trainer.update()\n",
    "    print(sum_of_losses / 3)\n",
    "    sum_of_losses = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.34042108  0.33031464  0.32926428]\n",
      "0 [ 0.34230351  0.33097464  0.32672185]\n",
      "0 [ 0.34670839  0.31679502  0.33649665]\n"
     ]
    }
   ],
   "source": [
    "# prediction code:\n",
    "for sequence in [(1,4,12,1), (42,1), (56,2,17)]:\n",
    "    dy.renew_cg() # new computation graph\n",
    "    vecs = [embeds[i] for i in sequence]\n",
    "    preds = dy.softmax(acceptor(vecs))\n",
    "    vals  = preds.npvalue()\n",
    "    print(np.argmax(vals), vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48097262]\n",
      "[ 0.44454539]\n",
      "[ 0.41038281]\n",
      "[ 0.37879309]\n",
      "[ 0.34985885]\n",
      "[ 0.32346082]\n",
      "[ 0.29933873]\n",
      "[ 0.27716547]\n",
      "[ 0.25661072]\n",
      "[ 0.23738393]\n"
     ]
    }
   ],
   "source": [
    "# LSTMAcceptor is the same as without batching\n",
    "\n",
    "# training code: batched.\n",
    "for epoch in range(10):\n",
    "    dy.renew_cg()     # we create a new computation graph for the epoch, not each item.\n",
    "    # we will treat all these 3 datapoints as a single batch\n",
    "    losses = []\n",
    "    for sequence,label in [((1,4,5,1),1), ((42,1),2), ((56,2,17),1)]:\n",
    "        vecs = [embeds[i] for i in sequence]\n",
    "        preds = acceptor(vecs)\n",
    "        loss = dy.pickneglogsoftmax(preds, label)\n",
    "        losses.append(loss)\n",
    "    # we accumulated the losses from all the batch.\n",
    "    # Now we sum them, and do forward-backward as usual.\n",
    "    # Things will run with efficient batch operations.\n",
    "    batch_loss = dy.esum(losses)/3\n",
    "    print(batch_loss.npvalue()) # this calls forward on the batch\n",
    "    batch_loss.backward()\n",
    "    trainer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 0.01109798  0.96727955  0.02162244]\n",
      "2 [ 0.18580519  0.2743032   0.5398916 ]\n",
      "1 [ 0.01701832  0.96555424  0.01742738]\n"
     ]
    }
   ],
   "source": [
    "# prediction code:\n",
    "dy.renew_cg() # new computation graph\n",
    "batch_preds = []\n",
    "for sequence in [(1,4,12,1), (42,1), (56,2,17)]:\n",
    "    vecs = [embeds[i] for i in sequence]\n",
    "    preds = dy.softmax(acceptor(vecs))\n",
    "    batch_preds.append(preds)\n",
    "\n",
    "# now that we accumulated the prediction expressions,\n",
    "# we run forward on all of them:\n",
    "dy.forward(batch_preds)\n",
    "# and now we can efficiently access the individual values:\n",
    "for preds in batch_preds:\n",
    "    vals  = preds.npvalue()\n",
    "    print(np.argmax(vals), vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
