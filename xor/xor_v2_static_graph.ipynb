{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static network\n",
    "import dynet as dy\n",
    "\n",
    "# multilayer perceptron with a single hidden layer\n",
    "# input 2 nodes\n",
    "# hidden layer: 8 nodes, activation: tanh\n",
    "# output layer: 1 node\n",
    "# Ïƒ(V(tanh(Wx+b)))\n",
    "# x: 2x1\n",
    "# W: 8x2\n",
    "# b: 8 vector\n",
    "# V: 1x8\n",
    "\n",
    "# define the parameters\n",
    "m = dy.ParameterCollection()\n",
    "pW = m.add_parameters((8,2)) # _dynet.Parameters\n",
    "pV = m.add_parameters((1,8))\n",
    "pb = m.add_parameters((8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dynet.ComputationGraph at 0x10ab6bb40>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy.renew_cg() # new computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the parameters to the graph\n",
    "# create Expression representing the network \n",
    "#(the network will include the Expressions \n",
    "# for the Parameters defined in the parameter collection)\n",
    "W = dy.parameter(pW) #W is of type _dynet.Expression\n",
    "V = dy.parameter(pV)\n",
    "b = dy.parameter(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.dimension: ((8, 2), 1)\n",
      "b.dimension: ((8,), 1)\n",
      "V.dimension: ((1, 8), 1)\n"
     ]
    }
   ],
   "source": [
    "print('W.dimension: {}'.format(W.dim()))\n",
    "print('b.dimension: {}'.format(b.dim()))\n",
    "print('V.dimension: {}'.format(V.dim()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "x = dy.vecInput(2) # an input vector of size 2. _dynet._vecInputExpression\n",
    "output = dy.logistic(V*(dy.tanh((W*x)+b))) # output is _dynet.Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_dynet._vecInputExpression'>\n",
      "<class '_dynet.Expression'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(type(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8,), 1)\n",
      "((8,), 1)\n",
      "((1,), 1)\n",
      "((1,), 1)\n",
      "((1,), 1)\n"
     ]
    }
   ],
   "source": [
    "print((W*x+b).dim())\n",
    "print(dy.tanh((W*x+b)).dim())\n",
    "print((V*dy.tanh((W*x+b))).dim())\n",
    "print(dy.logistic(V*dy.tanh((W*x+b))).dim())\n",
    "print(output.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6489945650100708"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now query our network\n",
    "x.set([0,0])\n",
    "output.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to be able to define a loss, so we need an input expression to work against.\n",
    "y = dy.scalarInput(0) # this will hold the correct answer\n",
    "loss = dy.binary_log_loss(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_dynet._inputExpression'>\n",
      "<class '_dynet.Expression'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(type(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = dy.SimpleSGDTrainer(m)\n",
    "# trainer = dy.CyclicalSGDTrainer(m)\n",
    "# trainer = dy.AdamTrainer(m)\n",
    "# trainer = dy.AdagradTrainer(m)\n",
    "trainer = dy.RMSPropTrainer(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_dynet.RMSPropTrainer"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010000000474974513"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss before step is: 0.6511291265487671\n",
      "the loss after step is: 0.6370114088058472\n"
     ]
    }
   ],
   "source": [
    "# single step optimization/training\n",
    "\n",
    "x.set([1,0])\n",
    "y.set(1)\n",
    "loss_value = loss.value() # this performs a forward through the network.\n",
    "print(\"the loss before step is:\",loss_value)\n",
    "\n",
    "# now do an optimization step\n",
    "loss.backward()  # compute the gradients\n",
    "trainer.update()\n",
    "\n",
    "# see how it affected the loss:\n",
    "loss_value = loss.value(recalculate=True) # recalculate=True means \"don't use precomputed value\"\n",
    "print(\"the loss after step is:\",loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data set\n",
    "def create_xor_instances(num_rounds=2000):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for round in range(num_rounds):\n",
    "        for x1 in 0,1:\n",
    "            for x2 in 0,1:\n",
    "                answer = 0 if x1==x2 else 1\n",
    "                questions.append((x1,x2))\n",
    "                answers.append(answer)\n",
    "    return questions, answers\n",
    "\n",
    "questions, answers = create_xor_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n",
      "[(0, 0), (0, 1), (1, 0), (1, 1)]\n",
      "[0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(questions))\n",
    "print(len(answers))\n",
    "print(questions[:4])\n",
    "print(answers[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss is: 5.314767573509016e-05\n",
      "average loss is: 5.154752720955002e-05\n",
      "average loss is: 5.004935352189932e-05\n",
      "average loss is: 4.8644935327502024e-05\n",
      "average loss is: 4.732378857806907e-05\n",
      "average loss is: 4.608022316157682e-05\n",
      "average loss is: 4.490785400776076e-05\n",
      "average loss is: 4.3800606749755386e-05\n",
      "average loss is: 4.2753403744831705e-05\n",
      "average loss is: 4.176138444745448e-05\n",
      "average loss is: 4.082021563425025e-05\n",
      "average loss is: 3.992632509834948e-05\n",
      "average loss is: 3.9075942568160825e-05\n",
      "average loss is: 3.826587290859607e-05\n",
      "average loss is: 3.749331663736181e-05\n",
      "average loss is: 3.675577444596456e-05\n",
      "average loss is: 3.605085012114775e-05\n",
      "average loss is: 3.537632465496346e-05\n",
      "average loss is: 3.473029973256895e-05\n",
      "average loss is: 3.411093204658755e-05\n",
      "average loss is: 3.351655569314885e-05\n",
      "average loss is: 3.2945518753628924e-05\n",
      "average loss is: 3.239659095371557e-05\n",
      "average loss is: 3.186850319404281e-05\n",
      "average loss is: 3.1359918340240254e-05\n",
      "average loss is: 3.086975721159363e-05\n",
      "average loss is: 3.039707747929141e-05\n",
      "average loss is: 2.9940892956931618e-05\n",
      "average loss is: 2.9500322338647272e-05\n",
      "average loss is: 2.9074481038757465e-05\n",
      "average loss is: 2.8662634958011274e-05\n",
      "average loss is: 2.8264146244225686e-05\n",
      "average loss is: 2.787833381758405e-05\n",
      "average loss is: 2.7504524757258717e-05\n",
      "average loss is: 2.714217891428104e-05\n",
      "average loss is: 2.6790758592293666e-05\n",
      "average loss is: 2.6449758510401858e-05\n",
      "average loss is: 2.6118682341180638e-05\n",
      "average loss is: 2.579704434071736e-05\n",
      "average loss is: 2.54844641708587e-05\n",
      "average loss is: 2.5180548287696694e-05\n",
      "average loss is: 2.4884931958695235e-05\n",
      "average loss is: 2.459725614149055e-05\n",
      "average loss is: 2.431718699468051e-05\n",
      "average loss is: 2.4044415305676617e-05\n",
      "average loss is: 2.3778655573729022e-05\n",
      "average loss is: 2.351960324128239e-05\n",
      "average loss is: 2.3267028466591456e-05\n",
      "average loss is: 2.3020628968879464e-05\n",
      "average loss is: 2.2780219293508708e-05\n",
      "average loss is: 2.2545557122683414e-05\n",
      "average loss is: 2.2316392404578575e-05\n",
      "average loss is: 2.209257187561614e-05\n",
      "average loss is: 2.1873885105092255e-05\n",
      "average loss is: 2.1660167171582793e-05\n",
      "average loss is: 2.145121066657144e-05\n",
      "average loss is: 2.1246872164131978e-05\n",
      "average loss is: 2.104698694610902e-05\n",
      "average loss is: 2.085140952689379e-05\n",
      "average loss is: 2.0659973579919703e-05\n",
      "average loss is: 2.0472550413465856e-05\n",
      "average loss is: 2.0289010416813508e-05\n",
      "average loss is: 2.0109240029211964e-05\n",
      "average loss is: 1.9933093746544727e-05\n",
      "average loss is: 1.9760500277558235e-05\n",
      "average loss is: 1.9591281935790353e-05\n",
      "average loss is: 1.942539580788923e-05\n",
      "average loss is: 1.9262722208649766e-05\n",
      "average loss is: 1.9103147566135665e-05\n",
      "average loss is: 1.8946598472017025e-05\n",
      "average loss is: 1.8792970159845193e-05\n",
      "average loss is: 1.8642181150312353e-05\n",
      "average loss is: 1.8494161548204992e-05\n",
      "average loss is: 1.8348820677860008e-05\n",
      "average loss is: 1.8206079752114118e-05\n",
      "average loss is: 1.8065887688743188e-05\n",
      "average loss is: 1.7928156938411687e-05\n",
      "average loss is: 1.7792811005655006e-05\n",
      "average loss is: 1.765977754455636e-05\n",
      "average loss is: 1.7529032507525244e-05\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "total_loss = 0\n",
    "seen_instances = 0\n",
    "for question, answer in zip(questions, answers):\n",
    "    x.set(question)\n",
    "    y.set(answer)\n",
    "    seen_instances += 1\n",
    "    total_loss += loss.value() # forward\n",
    "    loss.backward()\n",
    "    trainer.update()\n",
    "    if (seen_instances > 1 and seen_instances % 100 == 0):\n",
    "        print(\"average loss is:\",total_loss / seen_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1 0.9999913573265076\n",
      "1,0 0.9999917149543762\n",
      "0,0 4.5227275222714525e-06\n",
      "1,1 7.1626768658461515e-06\n"
     ]
    }
   ],
   "source": [
    "x.set([0,1])\n",
    "print(\"0,1\",output.value())\n",
    "\n",
    "x.set([1,0])\n",
    "print(\"1,0\",output.value())\n",
    "\n",
    "x.set([0,0])\n",
    "print(\"0,0\",output.value())\n",
    "\n",
    "x.set([1,1])\n",
    "print(\"1,1\",output.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.07663822, -2.77607584],\n",
       "       [ 2.17588735, -3.42900205],\n",
       "       [ 3.63992882,  3.72946382],\n",
       "       [ 0.06008036, -1.52189255],\n",
       "       [-3.54680562,  2.17219925],\n",
       "       [ 1.74713027, -2.989784  ],\n",
       "       [-0.82024181, -0.7913931 ],\n",
       "       [ 4.60517788,  4.43824816]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26245904,  0.91464269,  1.09329867,  0.70665795,  1.29633462,\n",
       "         1.35833979,  0.8188495 ,  1.72384453]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6605279445648193,\n",
       " -0.45908284187316895,\n",
       " -0.1739916205406189,\n",
       " 0.2111283540725708,\n",
       " -0.35437655448913574,\n",
       " -0.33467215299606323,\n",
       " 0.3537399470806122,\n",
       " -0.7486727237701416]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('models/xor_static_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
